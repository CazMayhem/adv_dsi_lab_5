{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Neural Networks**\n",
    "\n",
    "## Exercise 3: Multi-Class Classification with Pytorch\n",
    "\n",
    "In this exercise, we will build a a Neural Networks with Pytorch for predicting car evaluation. We will be woking on the Car dataset:\n",
    "https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv\n",
    "\n",
    "\n",
    "The steps are:\n",
    "1.   Setup Repository\n",
    "2.   Load and Explore Dataset\n",
    "3.   Prepare Data\n",
    "4.   Baseline Model\n",
    "5.   Define Architecture\n",
    "6.   Train Model\n",
    "7.   Push Changes\n",
    "\n",
    "**[1.1]** Go inside the created folder `adv_dsi_lab_5`\n",
    "\n",
    "**[1.2]** Create a new git branch called `pytorch_multi_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go inside the created folder adv_dsi_lab_5\n",
    "cd adv_dsi_lab_5\n",
    "\n",
    "# Create a new git branch called pytorch_multi_class\n",
    "git checkout -b pytorch_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1.2]** Run the built image\n",
    "\n",
    "**[1.3]** Display last 50 lines of logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run  -dit --rm --name adv_dsi_lab_5 -p 8888:8888 -e JUPYTER_ENABLE_LAB=yes \n",
    "-v ~/Projects/adv_dsi/adv_dsi_lab_5:/home/jovyan/work \n",
    "-v ~/Projects/adv_dsi/src:/home/jovyan/work/src \n",
    "-v ~/Projects/adv_dsi/data:/home/jovyan/work/data \n",
    "pytorch-notebook:latest \n",
    "    \n",
    "docker logs --tail 50 adv_dsi_lab_5            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.   Load and Explore Dataset\n",
    "\n",
    "**[2.1]** Launch the magic commands for auto-relaoding external modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the magic commands for auto-relaoding external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.2]** Import the pandas and numpy packages\n",
    "\n",
    "**[2.3]** Create a variable called `file_url` containing th url to the raw dataset\n",
    "\n",
    "**[2.4]** Load the data in a dataframe called `df`\n",
    "\n",
    "**[2.5]** Display the first 5 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying_price maintenance_cost doors persons_capacity luggage_boot safety  \\\n",
       "0        vhigh            vhigh     2                2        small    low   \n",
       "1        vhigh            vhigh     2                2        small    med   \n",
       "2        vhigh            vhigh     2                2        small   high   \n",
       "3        vhigh            vhigh     2                2          med    low   \n",
       "4        vhigh            vhigh     2                2          med    med   \n",
       "\n",
       "  evaluation  \n",
       "0      unacc  \n",
       "1      unacc  \n",
       "2      unacc  \n",
       "3      unacc  \n",
       "4      unacc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# variable called file_url containing th url to the raw dataset\n",
    "file_url = 'https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv'\n",
    "\n",
    "# Load the data in a dataframe called df\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Display the first 5 rows of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.6]** Display the dimensions (shape) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dimensions (shape) of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.7]** Display the summary (info) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying_price        1728 non-null object\n",
      "maintenance_cost    1728 non-null object\n",
      "doors               1728 non-null object\n",
      "persons_capacity    1728 non-null object\n",
      "luggage_boot        1728 non-null object\n",
      "safety              1728 non-null object\n",
      "evaluation          1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the summary (info) of df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.8]** Display the descriptive statistics of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying_price maintenance_cost doors persons_capacity luggage_boot  \\\n",
       "count          1728             1728  1728             1728         1728   \n",
       "unique            4                4     4                3            3   \n",
       "top             med              med     2                2          med   \n",
       "freq            432              432   432              576          576   \n",
       "\n",
       "       safety evaluation  \n",
       "count    1728       1728  \n",
       "unique      3          4  \n",
       "top       med      unacc  \n",
       "freq      576       1210  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statictics of df\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.9]** Save the dataframe locally in the `data/raw` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe locally in the data/raw folder\n",
    "df.to_csv('../data/raw/car_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Data\n",
    "\n",
    "**[3.1]** Create a copy of `df` and save it into a variable called `df_cleaned`\n",
    "\n",
    "**[3.2]** Create a dictionary called `cats_dict` that contains the categorical variables as keys and their respective values sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Create a dictionary called cats_dict that contains the categorical variables as keys and their respective values sorted in ascending order\n",
    "cats_dict = {\n",
    "    'buying_price': [['low', 'med', 'high', 'vhigh']],\n",
    "    'maintenance_cost': [['low', 'med', 'high', 'vhigh']],\n",
    "    'doors': [['2', '3', '4', '5more']],\n",
    "    'persons_capacity': [['2', '4', 'more']],\n",
    "    'luggage_boot': [['small', 'med', 'big']],\n",
    "    'safety': [['low', 'med', 'high']],\n",
    "    'evaluation': [['unacc', 'acc', 'good', 'vgood']],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.3]** Import `StandardScaler` and `OrdinalEncoder` from `sklearn.preprocessing`\n",
    "\n",
    "**[3.4]** Iterate through the elements of `cast_dict`, instantiate an OrdinalEncoder() and transform the values of each column with this encoder\n",
    "\n",
    "**[3.5]** Create a list called `num_cols` that contains all numeric columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler and OrdinalEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# Iterate through the elements of cast_dict, instantiate an OrdinalEncoder() and transform the values of each column with this encoder\n",
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])\n",
    "    \n",
    "# Create a list called num_cols that contains all numeric columns\n",
    "num_cols = ['buying_price', 'maintenance_cost', 'doors', 'persons_capacity', 'luggage_boot', 'safety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.6]** Instantiate a `StandardScaler` and called it `sc`\n",
    "\n",
    "**[3.7]** Fit and transform the numeric feature of `df_cleaned` and replace the data into it\n",
    "\n",
    "**[3.8]** Convert the column `evaluation` as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric feature of X_train_cleaned and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])\n",
    "\n",
    "# Convert the column evaluation as integer\n",
    "df_cleaned['evaluation'] = df_cleaned['evaluation'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.9]** Import `split_sets_random` and `save_sets` from `src.data.sets`\n",
    "\n",
    "**[3.10]** Split the data into training and testing sets with 80-20 ratio\n",
    "\n",
    "**[3.11]** Create the following folder: ../data/processed/car_evaluation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import split_sets_random from sklearn.model_selection\n",
    "from src.data.sets import split_sets_random, save_sets\n",
    "\n",
    "# Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned, target_col='evaluation', test_ratio=0.2)\n",
    "\n",
    "!mkdir ../data/processed/car_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.12]** Save the sets in the `data/processed/car_evaluation` folder\n",
    "\n",
    "**[3.13]** Import this class from `src/models/pytorch` and convert all sets to PytorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sets in the data/processed/car_evaluation folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, \n",
    "          path='../data/processed/car_evaluation/')\n",
    "\n",
    "# Import this class from src/models/pytorch and convert all sets to PytorchDataset\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baseline Model\n",
    "\n",
    "**[4.1]** Import `NullModel` from `src.models.null`\n",
    "\n",
    "**[4.2]** Instantiate a `NullModel` and call `.fit_predict()` on the training target to extract your predictions into a variable called `y_base`\n",
    "\n",
    "**[4.3]** Import `print_class_perf` from `src.models.performance`\n",
    "\n",
    "**[4.4]** Print the classification metrics for this baseline model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.6988416988416989\n",
      "F1 Training: 0.5749561249561249\n"
     ]
    }
   ],
   "source": [
    "# Import NullModel from src.models.null\n",
    "from src.models.null import NullModel\n",
    "\n",
    "# Instantiate a NullModel and call .fit_predict() on the training target to extract \n",
    "# your predictions into a variable called y_base\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)\n",
    "\n",
    "# Import print_class_perf from src.models.performance\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "# Print the classification metrics for this baseline model\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Architecture\n",
    "\n",
    "**[5.1]** Create in `src/models/pytorch.py` a class called `PytorchMultiClass` that inherits from `nn.Module` with:\n",
    "- `num_features` as input parameter\n",
    "- attributes:\n",
    "    - `layer_1`: fully-connected layer with 32 neurons\n",
    "    - `layer_out`: fully-connected layer with 4 neurons\n",
    "    - `softmax`: softmax function\n",
    "- methods:\n",
    "    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer with softmax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5.2]** Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`\n",
    "\n",
    "**[5.3]** Instantiate `PytorchMultiClass` with the correct number of input feature and save it into a variable called `model`\n",
    "\n",
    "**[5.4]** Import get_device() from `src.models.pytorch` and set model to use the device available\n",
    "\n",
    "**[5.5]** Print the architecture of `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Instantiate PytorchMultiClass with the correct number of input feature and save it into a variable called model\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n",
    "\n",
    "# Print the architecture of model\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train Model\n",
    "\n",
    "**[6.1]** Instantiate a `nn.CrossEntropyLoss()` and save it into a variable called `criterion` \n",
    "\n",
    "**[6.2]** Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.1 as learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a nn.CrossEntropyLoss() and save it into a variable called criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.1 as learning rate\n",
    "# and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6.3]** Create a function called `train_classification()` that will perform forward and back propagation and calculate loss and Accuracy scores\n",
    "\n",
    "**[6.5]** Create a function called `test_classification()` that will perform forward and calculate loss and accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6.5]** Create 2 variables called `N_EPOCHS` and `BATCH_SIZE` that will take respectively 50 and 32 as values\n",
    "\n",
    "**[6.6]** Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.0340\t|\tAcc: 67.9%\n",
      "\t(valid)\t|\tLoss: 0.0332\t|\tAcc: 69.4%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.0318\t|\tAcc: 73.6%\n",
      "\t(valid)\t|\tLoss: 0.0301\t|\tAcc: 79.5%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.0306\t|\tAcc: 77.7%\n",
      "\t(valid)\t|\tLoss: 0.0298\t|\tAcc: 80.1%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.0302\t|\tAcc: 78.8%\n",
      "\t(valid)\t|\tLoss: 0.0291\t|\tAcc: 82.1%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.4%\n",
      "\t(valid)\t|\tLoss: 0.0288\t|\tAcc: 83.8%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.3%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 85.8%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0283\t|\tAcc: 85.3%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 85.4%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.6%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.0%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.4%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.1%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.9%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.6%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 86.7%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.7%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.8%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.0%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.3%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 86.7%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.7%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.4%\n",
      "Epoch: 20\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.2%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 87.9%\n",
      "Epoch: 21\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.4%\n",
      "Epoch: 22\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 86.0%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.3%\n",
      "Epoch: 23\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 86.7%\n",
      "Epoch: 24\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 86.5%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.4%\n",
      "Epoch: 25\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 87.0%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 84.4%\n",
      "Epoch: 26\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 86.2%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 84.4%\n",
      "Epoch: 27\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.6%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.3%\n",
      "Epoch: 28\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.7%\n",
      "Epoch: 29\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.8%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 30\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.8%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.3%\n",
      "Epoch: 31\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.0%\n",
      "Epoch: 32\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.7%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.2%\n",
      "Epoch: 33\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.4%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 87.9%\n",
      "Epoch: 34\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.2%\n",
      "Epoch: 35\n",
      "\t(train)\t|\tLoss: 0.0273\t|\tAcc: 88.6%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.4%\n",
      "Epoch: 36\n",
      "\t(train)\t|\tLoss: 0.0274\t|\tAcc: 88.4%\n",
      "\t(valid)\t|\tLoss: 0.0270\t|\tAcc: 89.3%\n",
      "Epoch: 37\n",
      "\t(train)\t|\tLoss: 0.0274\t|\tAcc: 88.4%\n",
      "\t(valid)\t|\tLoss: 0.0270\t|\tAcc: 89.6%\n",
      "Epoch: 38\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.6%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 87.9%\n",
      "Epoch: 39\n",
      "\t(train)\t|\tLoss: 0.0275\t|\tAcc: 88.2%\n",
      "\t(valid)\t|\tLoss: 0.0270\t|\tAcc: 89.6%\n",
      "Epoch: 40\n",
      "\t(train)\t|\tLoss: 0.0273\t|\tAcc: 88.5%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 88.2%\n",
      "Epoch: 41\n",
      "\t(train)\t|\tLoss: 0.0271\t|\tAcc: 89.1%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 42\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.6%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.2%\n",
      "Epoch: 43\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 44\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.7%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.0%\n",
      "Epoch: 45\n",
      "\t(train)\t|\tLoss: 0.0274\t|\tAcc: 88.1%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 46\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 87.1%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 87.3%\n",
      "Epoch: 47\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 48\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 87.9%\n",
      "Epoch: 49\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 87.9%\n"
     ]
    }
   ],
   "source": [
    "# variables N_EPOCHS and BATCH_SIZE that will take respectively 50 and 32 as values\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a for loop that will iterate through the specified number of epochs and will train the model\n",
    "# with the training set and assess the performance on the validation set and print their scores\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6.7]** Save the model into the `models` folder\n",
    "\n",
    "**[6.8]** Assess the model performance on the testing set and print its scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.0285\t|\tAccuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Save the model into the models folder\n",
    "torch.save(model, \"../models/pytorch_multi_car_evaluation.pt\")\n",
    "\n",
    "# Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.   Push changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Add your changes to git staging area\n",
    "git add .\n",
    "\n",
    "# Create the snapshot of your repository and add a description\n",
    "git commit -m \"pytorch regression\"\n",
    "\n",
    "# Push your snapshot to Github\n",
    "git push https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "# Check out to the master branch\n",
    "git checkout master\n",
    "\n",
    "# Pull the latest updates\n",
    "git pull https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "# Merge the branch pytorch_reg\n",
    "git checkout pytorch_multi_class\n",
    "\n",
    "# Merge the master branch and push your changes, \n",
    "# any merge issues use:  git merge master --allow-unrelated-histories\n",
    "git merge master \n",
    "git push https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
