{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Neural Networks**\n",
    "\n",
    "## Exercise 1: Regression with Pytorch\n",
    "\n",
    "In this exercise, we will build a Neural Networks with Pytorch for predicting pollution level. We will be working on the Beijing Pollution dataset:\n",
    "https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Beijing%20PM2.5\n",
    "\n",
    "The steps are:\n",
    "1.   Setup Repository\n",
    "2.   Load and Explore Dataset\n",
    "3.   Prepare Data\n",
    "4.   Baseline Model\n",
    "5.   Define Architecture\n",
    "6.   Create Data Loader\n",
    "7.   Train Model\n",
    "8.   Assess Performance\n",
    "9.   Push Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup Repository\n",
    "\n",
    "**[1.1]** Go to a folder of your choice on your computer (where you store projects)\n",
    "\n",
    "**[1.2]** Copy the cookiecutter data science template\n",
    "- Follow the prompt (name the project and repo adv_dsi_lab_5)\n",
    "\n",
    "**[1.3]** Go inside the created folder `adv_dsi_lab_5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to a folder of your choice on your computer (where you store projects)\n",
    "cd ~/Projects/\n",
    "\n",
    "# Copy the cookiecutter data science template\n",
    "cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science\n",
    "    \n",
    "# Go inside the created folder adv_dsi_lab_5\n",
    "cd adv_dsi_lab_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1.4]** Create a file called `Dockerfile` and add the following content:\n",
    "\n",
    "`FROM jupyter/scipy-notebook:0ce64578df46`\n",
    "\n",
    "`RUN pip install torch==1.9.0+cpu torchvision==0.10.0+cpu torchtext==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "`ENV PYTHONPATH \"${PYTHONPATH}:/home/jovyan/work\"`\n",
    "\n",
    "`RUN echo \"export PYTHONPATH=/home/jovyan/work\" >> ~/.bashrc`\n",
    "\n",
    "`WORKDIR /home/jovyan/work`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1.5]** Build the image from this Dockerfile\n",
    "\n",
    "**[1.6]** Run the built image\n",
    "\n",
    "**[1.7]** Display last 50 lines of logs\n",
    "- Copy the url displayed and paste it to a browser in order to launch Jupyter Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the image from this Dockerfile\n",
    "docker build -t pytorch-notebook:latest .\n",
    "    \n",
    "# Run the built image\n",
    "docker run  -dit --rm --name adv_dsi_lab_5 -p 8888:8888 -e JUPYTER_ENABLE_LAB=yes \n",
    "-v ~/Projects/adv_dsi/adv_dsi_lab_5:/home/jovyan/work \n",
    "-v ~/Projects/adv_dsi/src:/home/jovyan/work/src \n",
    "-v ~/Projects/adv_dsi/data:/home/jovyan/work/data \n",
    "pytorch-notebook:latest  \n",
    "    \n",
    "# Display last 50 lines of logs\n",
    "docker logs --tail 50 adv_dsi_lab_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1.8]** Initialise the repo\n",
    "\n",
    "**[1.9]** Login into Github with your account (https://github.com/) and create a public repo with the name `adv_dsi_lab_5`\n",
    "\n",
    "**[1.10]** In your local repo `adv_dsi_lab_5`, link it with Github (replace the url with your username)\n",
    "\n",
    "**[1.11]** Add your changes to git staging area and commit them\n",
    "\n",
    "**[1.12]** Push your master branch to origin\n",
    "\n",
    "**[1.13]** Preventing push to `master` branch\n",
    "\n",
    "**[1.14]** Create a new git branch called `pytorch_reg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Initialise the repo\n",
    "git init\n",
    "\n",
    "# Login into Github with your account (https://github.com/) \n",
    "# and create a public repo with the name `adv_dsi_lab_5`\n",
    "\n",
    "# Link repo with Github\n",
    "git remote add origin git@github.com:CazMayhem/adv_dsi_lab_1_5.git\n",
    "\n",
    "# Add your changes to git staging area and commit them\n",
    "git add .\n",
    "git commit -m \"init\"\n",
    "\n",
    "# Push your master branch to origin\n",
    "git push https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git --set-upstream origin master\n",
    "\n",
    "# Preventing push to master branch\n",
    "git config branch.master.pushRemote no_push\n",
    "\n",
    "# Create a new git branch called pytorch_reg\n",
    "git checkout -b pytorch_reg\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.   Load and Explore Dataset\n",
    "**[2.1]** Download the dataset into the `data/raw` folder:https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-19 00:14:47--  https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv\n",
      "Resolving code.datasciencedojo.com (code.datasciencedojo.com)... 167.99.111.153\n",
      "Connecting to code.datasciencedojo.com (code.datasciencedojo.com)|167.99.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1966669 (1.9M) [text/plain]\n",
      "Saving to: ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv.1’\n",
      "\n",
      "PRSA_data_2010.1.1- 100%[===================>]   1.88M  1.39MB/s    in 1.3s    \n",
      "\n",
      "2022-03-19 00:14:50 (1.39 MB/s) - ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv.1’ saved [1966669/1966669]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ../data/raw https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.2]** Launch the magic commands for auto-relaoding external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.3]** Import the pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data in a dataframe called df\n",
    "df = pd.read_csv('../data/raw/PRSA_data_2010.1.1-2014.12.31.csv')\n",
    "\n",
    "# Display the first 5 rows of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43824, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dimensions (shape) of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43824 entries, 0 to 43823\n",
      "Data columns (total 13 columns):\n",
      "No       43824 non-null int64\n",
      "year     43824 non-null int64\n",
      "month    43824 non-null int64\n",
      "day      43824 non-null int64\n",
      "hour     43824 non-null int64\n",
      "pm2.5    41757 non-null float64\n",
      "DEWP     43824 non-null int64\n",
      "TEMP     43824 non-null float64\n",
      "PRES     43824 non-null float64\n",
      "cbwd     43824 non-null object\n",
      "Iws      43824 non-null float64\n",
      "Is       43824 non-null int64\n",
      "Ir       43824 non-null int64\n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display the summary (info) of df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>6.523549</td>\n",
       "      <td>15.727820</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>98.613215</td>\n",
       "      <td>1.817246</td>\n",
       "      <td>12.448521</td>\n",
       "      <td>1016.447654</td>\n",
       "      <td>23.889140</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.194916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12651.043435</td>\n",
       "      <td>1.413842</td>\n",
       "      <td>3.448572</td>\n",
       "      <td>8.799425</td>\n",
       "      <td>6.922266</td>\n",
       "      <td>92.050387</td>\n",
       "      <td>14.433440</td>\n",
       "      <td>12.198613</td>\n",
       "      <td>10.268698</td>\n",
       "      <td>50.010635</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>1.415867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10956.750000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32868.250000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>585.600000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 No          year         month           day          hour  \\\n",
       "count  43824.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean   21912.500000   2012.000000      6.523549     15.727820     11.500000   \n",
       "std    12651.043435      1.413842      3.448572      8.799425      6.922266   \n",
       "min        1.000000   2010.000000      1.000000      1.000000      0.000000   \n",
       "25%    10956.750000   2011.000000      4.000000      8.000000      5.750000   \n",
       "50%    21912.500000   2012.000000      7.000000     16.000000     11.500000   \n",
       "75%    32868.250000   2013.000000     10.000000     23.000000     17.250000   \n",
       "max    43824.000000   2014.000000     12.000000     31.000000     23.000000   \n",
       "\n",
       "              pm2.5          DEWP          TEMP          PRES           Iws  \\\n",
       "count  41757.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean      98.613215      1.817246     12.448521   1016.447654     23.889140   \n",
       "std       92.050387     14.433440     12.198613     10.268698     50.010635   \n",
       "min        0.000000    -40.000000    -19.000000    991.000000      0.450000   \n",
       "25%       29.000000    -10.000000      2.000000   1008.000000      1.790000   \n",
       "50%       72.000000      2.000000     14.000000   1016.000000      5.370000   \n",
       "75%      137.000000     15.000000     23.000000   1025.000000     21.910000   \n",
       "max      994.000000     28.000000     42.000000   1046.000000    585.600000   \n",
       "\n",
       "                 Is            Ir  \n",
       "count  43824.000000  43824.000000  \n",
       "mean       0.052734      0.194916  \n",
       "std        0.760375      1.415867  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       27.000000     36.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isplay the descriptive statictics of df\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Data\n",
    "\n",
    "**[3.1]** Create a copy of `df` and save it into a variable called `df_cleaned`\n",
    "\n",
    "**[3.2]** Remove the column `No` as it is an identifier for rows\n",
    "\n",
    "**[3.3]** Remove the missing values from the target variable `pm2.5`\n",
    "\n",
    "**[3.4]** Reset the indexes of the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Remove the column No as it is an identifier for rows\n",
    "df_cleaned.drop('No', axis=1, inplace=True)\n",
    "\n",
    "# Remove the missing values from the target variable pm2.5\n",
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "# Reset the indexes of the dataframe\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.5]** Import `StandardScaler` and `OneHotEncoder` from `sklearn.preprocessing`\n",
    "\n",
    "**[3.6]** Create a list called `num_cols` that contains `year`, `DEWP`, `TEMP`, `PRES`, `Iws`, `Is`, `Ir`\n",
    "\n",
    "**[3.7]** Instantiate a `StandardScaler` and called it `sc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler and OneHotEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Create a list called num_cols that contains year, DEWP, TEMP, PRES, Iws, Is, Ir\n",
    "num_cols = ['year', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']\n",
    "\n",
    "# Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.8]** Fit and transform the numeric feature of `df_cleaned` and replace the data into it\n",
    "\n",
    "**[3.9]** Create a list called `cat_cols` that contains `month`, `day`, `hour`, `cbwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the numeric feature of X_train_cleaned and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])\n",
    "\n",
    "# Create a list called cat_cols that contains Gender\n",
    "cat_cols = ['month', 'day', 'hour', 'cbwd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.10]** Instantiate a `OneHotEncoder` and called it `ohe`\n",
    "\n",
    "**[3.11]** Perform One-Hot encoding on `cat_cols` and save them into a dataframe called `X_cat`\n",
    "\n",
    "**[3.12]** Extract the feature names from `ohe` and replace the names of the columns of the `X_cat`\n",
    "\n",
    "**[3.13]** Drop the original columns of `cat_cols` from `df_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a OneHotEncoder and called it ohe\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Perform One-Hot encoding on cat_cols and save them into a dataframe called X_cat\n",
    "X_cat = pd.DataFrame(ohe.fit_transform(df_cleaned[cat_cols]))\n",
    "\n",
    "# Extract the feature names from ohe and replace the names of the columns of the X_cat\n",
    "X_cat.columns = ohe.get_feature_names(cat_cols)\n",
    "\n",
    "# Drop the original columns of cat_cols from df_cleaned\n",
    "df_cleaned.drop(cat_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.14]** Concatenate `df_cleaned` with `X_cat` and save the result to a variable called `X`\n",
    "\n",
    "**[3.15]** Import `split_sets_by_time` and `save_sets` from `src.data.sets`\n",
    "\n",
    "**[3.16]** Split the data into training and testing sets with 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df_cleaned with X_cat and save the result to a variable called X\n",
    "X = pd.concat([df_cleaned, X_cat], axis=1)\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "from src.data.sets import split_sets_by_time, save_sets\n",
    "\n",
    "# Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(X, target_col='pm2.5', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.17]** Create the following folder: `data/processed/beijing_pollution`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../data/processed’: File exists\n",
      "mkdir: cannot create directory ‘../data/processed/beijing_pollution’: File exists\n"
     ]
    }
   ],
   "source": [
    "# create the following folder: data/processed/beijing_pollution\n",
    "!mkdir ../data/processed\n",
    "!mkdir ../data/processed/beijing_pollution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3.18]** Save the sets in the `data/processed/beijing_pollution` folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sets in the data/processed/beijing_pollution folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, \n",
    "          path='../data/processed/beijing_pollution/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Model\n",
    "\n",
    "**[4.1]** Import `NullModel` from `src.models.null`\n",
    "\n",
    "**[4.2]** Instantiate a `NullModel` and call `.fit_predict()` on the training target to extract your predictions into a variable called `y_base`\n",
    "\n",
    "**[4.3]** Import `print_reg_perf` from `src.models.performance`\n",
    "\n",
    "**[4.4]** Print the regression metrics for this baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 92.82545840756482\n",
      "MAE Training : 69.67082209440568\n"
     ]
    }
   ],
   "source": [
    "# Import NullModel from src.models.null\n",
    "from src.models.null import NullModel\n",
    "\n",
    "# Instantiate a NullModel and call .fit_predict() on the training target \n",
    "# to extract your predictions into a variable called y_base\n",
    "baseline_model = NullModel()\n",
    "y_base = baseline_model.fit_predict(y_train)\n",
    "\n",
    "# Import print_reg_perf from src.models.performance\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "# Print the regression metrics for this baseline model\n",
    "print_reg_perf(y_base, y_train, set_name='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5.1]** Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`\n",
    "\n",
    "**[5.3]** Instantiate `PytorchRegression` with the correct number of input feature and save it into a variable called `model`\n",
    "\n",
    "**[5.5]** Set `model` to use the device available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchRegression(\n",
       "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Instantiate PytorchRegression with the correct number of input feature and save it into a variable called model\n",
    "from src.models.pytorch import PytorchRegression\n",
    "\n",
    "model = PytorchRegression(X_train.shape[1])\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Data Loader\n",
    "\n",
    "**[6.1]** Import `Dataset` and `DataLoader` from `torch.utils.data`\n",
    "\n",
    "**[6.3]** Import this class from `src/models/pytorch` and convert all sets to PytorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset and DataLoader from torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import this class from src/models/pytorch and convert all sets to PytorchDataset\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train Model\n",
    "\n",
    "**[7.1]** Instantiate a `nn.MSELoss()` and save it into a variable called `criterion` \n",
    "\n",
    "**[7.2]** Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called `optimizer`\n",
    "\n",
    "**[7.5]** Create 2 variables called `N_EPOCHS` and `BATCH_SIZE` that will take respectively 5 and 32 as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a nn.MSELoss() and save it into a variable called criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.001 as learning rate \n",
    "# and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Variables N_EPOCHS and BATCH_SIZE that will take respectively 5 and 32 as values\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[7.6]** Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 352.0528\t|\tRMSE: 18.8\n",
      "\t(valid)\tLoss: 249.2544\t|\tRMSE: 15.8\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 273.6801\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.7091\t|\tRMSE: 15.4\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 272.6869\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.6739\t|\tRMSE: 15.4\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 272.2375\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.9588\t|\tRMSE: 15.4\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 272.2680\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.3370\t|\tRMSE: 15.4\n"
     ]
    }
   ],
   "source": [
    "# Create a for loop that will iterate through the specified number of epochs and will train the model \n",
    "# with the training set and assess the performance on the validation set and print their scores\n",
    "from src.models.pytorch import train_regression, test_regression\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_rmse = train_regression(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_rmse = test_regression(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tRMSE: {train_rmse:.1f}')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tRMSE: {valid_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[7.7]** Save the model into the `models` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into the models folder\n",
    "torch.save(model, \"../models/pytorch_reg_pm2_5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.   Assess Performance\n",
    "\n",
    "**[8.1]** Assess the model performance on the testing set and print its scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 276.4697\t|\tRMSE: 16.6\n"
     ]
    }
   ],
   "source": [
    "# Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_rmse = test_regression(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tRMSE: {test_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.   Push changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Add your changes to git staging area\n",
    "git add .\n",
    "\n",
    "# Create the snapshot of your repository and add a description\n",
    "git commit -m \"pytorch regression\"\n",
    "\n",
    "# Push your snapshot to Github\n",
    "git push https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "# Check out to the master branch\n",
    "git checkout master\n",
    "\n",
    "# Pull the latest updates\n",
    "git pull https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "# Merge the branch pytorch_reg\n",
    "git checkout pytorch_reg\n",
    "\n",
    "# Merge the master branch and push your changes, \n",
    "# any merge issues use:  git merge master --allow-unrelated-histories\n",
    "git merge master \n",
    "git push https://<insert_pat>@github.com/CazMayhem/adv_dsi_lab_5.git\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Docker container\n",
    "docker stop adv_dsi_lab_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
